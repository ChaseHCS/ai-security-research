# Thought Manipulation

LLMs think. This means that they can be manipulated just like humans can. In fact, (at 07.25) it is much easier to manipulate LLMs than humans. There are many different terms for this `Prompt Injection`, `Chain of thought injection`, and others but I like to think of it all as manipulating the LLMs thoughts to make it operate outside of its intended use. Hence the term `Thought Manipulation`. 
